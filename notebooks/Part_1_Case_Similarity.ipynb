{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192df36e-7e09-488b-a0d1-469822faf7cb",
     "showTitle": false,
     "title": ""
    },
    "id": "TD7bDMhP6hAe",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:26:57.416080Z",
     "start_time": "2025-11-10T10:26:57.412106Z"
    }
   },
   "source": "# !pip install datasets",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0dff760-4279-47d4-a2e8-233d5763007f",
     "showTitle": false,
     "title": ""
    },
    "id": "qHLwOTCg6hAi"
   },
   "source": [
    "# Reading the Legal Cases Dataframe\n",
    "* case_id - represents a unique id for each case\n",
    "* text - represents the complaint text for each case\n",
    "* domain - the domain name of which this case belongs to"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0ee4df-aa09-4293-801f-6526dc026ceb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "E2N0f0mx6hAi",
    "outputId": "bc4f479a-2a1c-4893-e83a-0d5a83569364",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:37:48.318719Z",
     "start_time": "2025-11-10T10:37:41.545622Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('darrow-ai/legal-task')\n",
    "dataset = dataset['train'].to_pandas()\n",
    "dataset.head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronyg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     id                                               text  \\\n",
       "0  r-e4EYcBD5gMZwcz41zP  UNITED STATES DISTRICT COURT \\nEASTERN DISTRIC...   \n",
       "1  i9H5DocBD5gMZwcztj0y  IN THE UNITED STATES DISTRICT COURT \\nFOR THE ...   \n",
       "2  SMn3DYcBD5gMZwcz-hwH  IN THE UNITED STATES DISTRICT COURT\\n FOR THE ...   \n",
       "3  GMIWDYcBD5gMZwczDQBb  Case No. _______________ \\n \\n \\nCLASS ACTION ...   \n",
       "4  lELw_IgBF5pVm5zYONwC  UNITED STATES DISTRICT COURT \\n SOUTHERN DISTR...   \n",
       "\n",
       "                   domain  \n",
       "0          consumer fraud  \n",
       "1                 privacy  \n",
       "2                 privacy  \n",
       "3  criminal & enforcement  \n",
       "4          consumer fraud  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r-e4EYcBD5gMZwcz41zP</td>\n",
       "      <td>UNITED STATES DISTRICT COURT \\nEASTERN DISTRIC...</td>\n",
       "      <td>consumer fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i9H5DocBD5gMZwcztj0y</td>\n",
       "      <td>IN THE UNITED STATES DISTRICT COURT \\nFOR THE ...</td>\n",
       "      <td>privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMn3DYcBD5gMZwcz-hwH</td>\n",
       "      <td>IN THE UNITED STATES DISTRICT COURT\\n FOR THE ...</td>\n",
       "      <td>privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMIWDYcBD5gMZwczDQBb</td>\n",
       "      <td>Case No. _______________ \\n \\n \\nCLASS ACTION ...</td>\n",
       "      <td>criminal &amp; enforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lELw_IgBF5pVm5zYONwC</td>\n",
       "      <td>UNITED STATES DISTRICT COURT \\n SOUTHERN DISTR...</td>\n",
       "      <td>consumer fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:37:51.041668Z",
     "start_time": "2025-11-10T10:37:51.035557Z"
    }
   },
   "source": [
    "dataset.id.count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1204)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:38:28.518332Z",
     "start_time": "2025-11-10T10:38:28.504012Z"
    }
   },
   "source": [
    "dataset.groupby('domain').agg(\n",
    "    total_count=('id', 'count'),\n",
    "    distinct_count=('id', 'nunique')\n",
    ").sort_values('distinct_count', ascending=False)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       total_count  distinct_count\n",
       "domain                                                            \n",
       "consumer fraud                                 200             200\n",
       "securities                                     200             200\n",
       "privacy                                        200             200\n",
       "employment & labor                             200             200\n",
       "civil rights, immigration, family              167             167\n",
       "antitrust                                      126             126\n",
       "products liability and mass tort                56              56\n",
       "discrimination                                  20              20\n",
       "criminal & enforcement                          16              16\n",
       "healthcare                                       9               9\n",
       "intellectual property & communication            7               7\n",
       "environmental & natural resources                3               3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>distinct_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consumer fraud</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>securities</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privacy</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment &amp; labor</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civil rights, immigration, family</th>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antitrust</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>products liability and mass tort</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discrimination</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criminal &amp; enforcement</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthcare</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intellectual property &amp; communication</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmental &amp; natural resources</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:38:32.500877Z",
     "start_time": "2025-11-10T10:38:32.497674Z"
    }
   },
   "source": "# print(dataset.sample(1).text.iloc[0])\n",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67056f84-3563-4201-9c68-f5edc1ebcb62",
     "showTitle": false,
     "title": ""
    },
    "id": "bzHWWwF06hAj"
   },
   "source": "# Data Cleaning For Case Similarity"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Deduplication"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:38:33.831995Z",
     "start_time": "2025-11-10T10:38:33.165869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "print(\"Initial shape:\", dataset.shape)\n",
    "\n",
    "# Find all rows that are duplicated on the exact pair (id, text)\n",
    "dup_mask = dataset.duplicated(subset=[\"id\", \"text\"], keep=False)\n",
    "duplicates_df = dataset[dup_mask].copy()\n",
    "\n",
    "print(f\"Number of rows involved in [id, text] duplicates: {duplicates_df.shape[0]}\")\n",
    "\n",
    "# Save them for transparency / potential manual inspection\n",
    "if not duplicates_df.empty:\n",
    "    duplicates_df.to_csv(\"duplicates_id_text.csv\", index=False)\n",
    "    print(\"Saved [id, text] duplicates to 'duplicates_id_text.csv'.\")\n",
    "\n",
    "# Now create a deduplicated version keeping the first occurrence\n",
    "dataset_deduped = dataset.drop_duplicates(subset=[\"id\", \"text\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after deduplication on [id, text]:\", dataset_deduped.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (1204, 3)\n",
      "Number of rows involved in [id, text] duplicates: 0\n",
      "Shape after deduplication on [id, text]: (1204, 3)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb49c9a-819e-43d8-b56d-3b485803ee4c",
     "showTitle": false,
     "title": ""
    },
    "id": "9-IzeXvY6hAj",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:38:39.959561Z",
     "start_time": "2025-11-10T10:38:38.644936Z"
    }
   },
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Start from your deduped / filtered dataframe:\n",
    "# df has columns: id, text, domain\n",
    "\n",
    "def clean_for_similarity(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Light normalization for semantic similarity:\n",
    "    - ensure string\n",
    "    - normalize whitespace (incl. newlines) to single spaces\n",
    "    - strip\n",
    "    - lowercase\n",
    "    We keep punctuation and numbers – they can be informative in legal texts.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if text is None else str(text)\n",
    "\n",
    "    # Collapse all whitespace (spaces, tabs, newlines) into a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Lowercase for stability\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "dataset_deduped[\"text_clean_similarity\"] = dataset_deduped[\"text\"].apply(clean_for_similarity)\n",
    "\n",
    "# Build helper mappings\n",
    "case_ids = dataset_deduped[\"id\"].tolist()\n",
    "id_to_index = {cid: i for i, cid in enumerate(case_ids)}\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eca0720b-42e6-4acc-96a9-3b5afe9ba4f3",
     "showTitle": false,
     "title": ""
    },
    "id": "JPfBa4Qo6hAj"
   },
   "source": "# Part #1 - Similarity Calculation"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b28615e-c134-4ef0-bf58-9f5a58c45a37",
     "showTitle": false,
     "title": ""
    },
    "id": "kb9r-5ox6hAj",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:38:43.398964Z",
     "start_time": "2025-11-10T10:38:43.395381Z"
    }
   },
   "source": [
    "# def calculate_cases_similarity(case_id_a, case_id_b):\n",
    "#     '''\n",
    "#     This method should return a similarity score [0-1] that represents how similar the cases are\n",
    "#\n",
    "#     @param case_id_a - the id of the first case\n",
    "#     @param case_id_b - the id of the second case\n",
    "#     @returns a similarity score between the cases\n",
    "#     @rtype float\n",
    "#     '''\n",
    "#     pass"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> We compute case-to-case similarity using Sentence-Transformers rather than raw ```transformers```, as the former are explicitly trained for producing semantically meaningful sentence and document embeddings suitable for cosine-similarity comparison.\n",
    ">\n",
    "> Among available models, we selected ```all-MiniLM-L6-v2``` for its strong balance between semantic quality, speed, and hardware efficiency.\n",
    ">\n",
    "> While domain-specific models such as ```Legal-BERT``` exist, they are significantly heavier and optimized for fine-tuned downstream tasks rather than zero-shot semantic clustering. Given our dataset (~1 000 cases) and CPU-only environment, MiniLM provides near-state-of-the-art similarity performance with practical runtime."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6dbbb54-eb3c-41a1-a9f8-8575ab6513a1",
     "showTitle": false,
     "title": ""
    },
    "id": "koeB8NxI6hAj",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:39:28.696672Z",
     "start_time": "2025-11-10T10:38:46.797767Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# You can pick another suitable model if you like\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "similarity_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# Encode cleaned texts; normalize for direct cosine via dot product\n",
    "embeddings = similarity_model.encode(\n",
    "    dataset_deduped[\"text_clean_similarity\"].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# embeddings is a 2D numpy array: [n_cases, dim]\n",
    "embeddings = np.asarray(embeddings)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronyg\\workplace\\ds_position_darrow_ai\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ronyg\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Batches: 100%|██████████| 38/38 [00:22<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:39:50.762879Z",
     "start_time": "2025-11-10T10:39:50.757892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_cases_similarity(case_id_a, case_id_b):\n",
    "    '''\n",
    "    This method should return a similarity score [0-1] that represents how similar the cases are\n",
    "\n",
    "    @param case_id_a - the id of the first case\n",
    "    @param case_id_b - the id of the second case\n",
    "    @returns a similarity score between the cases\n",
    "    @rtype float\n",
    "    '''\n",
    "    # Ensure both IDs exist\n",
    "    idx_a = id_to_index.get(case_id_a)\n",
    "    idx_b = id_to_index.get(case_id_b)\n",
    "\n",
    "    if idx_a is None:\n",
    "        raise ValueError(f\"Unknown case_id_a: {case_id_a}\")\n",
    "    if idx_b is None:\n",
    "        raise ValueError(f\"Unknown case_id_b: {case_id_b}\")\n",
    "\n",
    "    # If same case → max similarity\n",
    "    if idx_a == idx_b:\n",
    "        return 1.0\n",
    "\n",
    "    vec_a = embeddings[idx_a]\n",
    "    vec_b = embeddings[idx_b]\n",
    "\n",
    "    # Cosine similarity for normalized vectors is just dot product in [-1, 1]\n",
    "    cos_sim = float(np.dot(vec_a, vec_b))\n",
    "\n",
    "    # Map from [-1, 1] to [0, 1], clamp for numerical stability\n",
    "    score = (cos_sim + 1.0) / 2.0\n",
    "    score = max(0.0, min(1.0, score))\n",
    "\n",
    "    return score\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:39:55.464515Z",
     "start_time": "2025-11-10T10:39:55.459592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quick sanity check\n",
    "\n",
    "# Pick two random IDs\n",
    "import random\n",
    "a, b = random.sample(case_ids, 2)\n",
    "print(a, b, calculate_cases_similarity(a, b))\n",
    "\n",
    "# Same ID should be 1.0\n",
    "print(a, a, calculate_cases_similarity(a, a))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i1EyBIkBRpLueGJZMLf9 deRdEYcBD5gMZwczFnnT 0.80626180768013\n",
      "i1EyBIkBRpLueGJZMLf9 i1EyBIkBRpLueGJZMLf9 1.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "interview_ds",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
