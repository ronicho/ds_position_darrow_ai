{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192df36e-7e09-488b-a0d1-469822faf7cb",
     "showTitle": false,
     "title": ""
    },
    "id": "TD7bDMhP6hAe",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:45:53.349179Z",
     "start_time": "2025-11-10T10:45:53.343556Z"
    }
   },
   "source": "# !pip install datasets",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:45:58.992442Z",
     "start_time": "2025-11-10T10:45:58.989680Z"
    }
   },
   "source": "# !pip install pandas",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41319e3f-0673-4d27-9b67-9b2f8908f05c",
     "showTitle": false,
     "title": ""
    },
    "id": "6vZ8ABcd6hAh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0ee4df-aa09-4293-801f-6526dc026ceb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "E2N0f0mx6hAi",
    "outputId": "bc4f479a-2a1c-4893-e83a-0d5a83569364",
    "ExecuteTime": {
     "end_time": "2025-11-10T10:46:11.689049Z",
     "start_time": "2025-11-10T10:46:04.652085Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('darrow-ai/legal-task')\n",
    "dataset = dataset['train'].to_pandas()\n",
    "dataset.head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronyg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     id                                               text  \\\n",
       "0  r-e4EYcBD5gMZwcz41zP  UNITED STATES DISTRICT COURT \\nEASTERN DISTRIC...   \n",
       "1  i9H5DocBD5gMZwcztj0y  IN THE UNITED STATES DISTRICT COURT \\nFOR THE ...   \n",
       "2  SMn3DYcBD5gMZwcz-hwH  IN THE UNITED STATES DISTRICT COURT\\n FOR THE ...   \n",
       "3  GMIWDYcBD5gMZwczDQBb  Case No. _______________ \\n \\n \\nCLASS ACTION ...   \n",
       "4  lELw_IgBF5pVm5zYONwC  UNITED STATES DISTRICT COURT \\n SOUTHERN DISTR...   \n",
       "\n",
       "                   domain  \n",
       "0          consumer fraud  \n",
       "1                 privacy  \n",
       "2                 privacy  \n",
       "3  criminal & enforcement  \n",
       "4          consumer fraud  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r-e4EYcBD5gMZwcz41zP</td>\n",
       "      <td>UNITED STATES DISTRICT COURT \\nEASTERN DISTRIC...</td>\n",
       "      <td>consumer fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i9H5DocBD5gMZwcztj0y</td>\n",
       "      <td>IN THE UNITED STATES DISTRICT COURT \\nFOR THE ...</td>\n",
       "      <td>privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMn3DYcBD5gMZwcz-hwH</td>\n",
       "      <td>IN THE UNITED STATES DISTRICT COURT\\n FOR THE ...</td>\n",
       "      <td>privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMIWDYcBD5gMZwczDQBb</td>\n",
       "      <td>Case No. _______________ \\n \\n \\nCLASS ACTION ...</td>\n",
       "      <td>criminal &amp; enforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lELw_IgBF5pVm5zYONwC</td>\n",
       "      <td>UNITED STATES DISTRICT COURT \\n SOUTHERN DISTR...</td>\n",
       "      <td>consumer fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:46:11.699201Z",
     "start_time": "2025-11-10T10:46:11.694820Z"
    }
   },
   "source": [
    "dataset.id.count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:46:21.989951Z",
     "start_time": "2025-11-10T10:46:21.981263Z"
    }
   },
   "source": [
    "dataset.groupby('domain').agg(\n",
    "    total_count=('id', 'count'),\n",
    "    distinct_count=('id', 'nunique')\n",
    ").sort_values('distinct_count', ascending=False)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       total_count  distinct_count\n",
       "domain                                                            \n",
       "consumer fraud                                 200             200\n",
       "securities                                     200             200\n",
       "privacy                                        200             200\n",
       "employment & labor                             200             200\n",
       "civil rights, immigration, family              167             167\n",
       "antitrust                                      126             126\n",
       "products liability and mass tort                56              56\n",
       "discrimination                                  20              20\n",
       "criminal & enforcement                          16              16\n",
       "healthcare                                       9               9\n",
       "intellectual property & communication            7               7\n",
       "environmental & natural resources                3               3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>distinct_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consumer fraud</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>securities</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privacy</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment &amp; labor</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civil rights, immigration, family</th>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antitrust</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>products liability and mass tort</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discrimination</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criminal &amp; enforcement</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthcare</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intellectual property &amp; communication</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmental &amp; natural resources</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:46:25.987471Z",
     "start_time": "2025-11-10T10:46:25.982992Z"
    }
   },
   "source": "# print(dataset.sample(1).text.iloc[0])\n",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67056f84-3563-4201-9c68-f5edc1ebcb62",
     "showTitle": false,
     "title": ""
    },
    "id": "bzHWWwF06hAj"
   },
   "source": "# Deduplication"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb49c9a-819e-43d8-b56d-3b485803ee4c",
     "showTitle": false,
     "title": ""
    },
    "id": "9-IzeXvY6hAj",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:46:54.695645Z",
     "start_time": "2025-11-10T11:46:53.949366Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "print(\"Initial shape:\", dataset.shape)\n",
    "\n",
    "# Find all rows that are duplicated on the exact pair (id, text)\n",
    "dup_mask = dataset.duplicated(subset=[\"id\", \"text\"], keep=False)\n",
    "duplicates_df = dataset[dup_mask].copy()\n",
    "\n",
    "print(f\"Number of rows involved in [id, text] duplicates: {duplicates_df.shape[0]}\")\n",
    "\n",
    "# Save them for transparency / potential manual inspection\n",
    "if not duplicates_df.empty:\n",
    "    duplicates_df.to_csv(\"duplicates_id_text.csv\", index=False)\n",
    "    print(\"Saved [id, text] duplicates to 'duplicates_id_text.csv'.\")\n",
    "\n",
    "# Now create a deduplicated version keeping the first occurrence\n",
    "dataset_deduped = dataset.drop_duplicates(subset=[\"id\", \"text\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after deduplication on [id, text]:\", dataset_deduped.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (1204, 3)\n",
      "Number of rows involved in [id, text] duplicates: 0\n",
      "Shape after deduplication on [id, text]: (1204, 3)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d01e04e2-16be-42ad-a704-a9ea963c42e6",
     "showTitle": false,
     "title": ""
    },
    "id": "Mzc_GlSN6hAj"
   },
   "cell_type": "markdown",
   "source": [
    "# Modeling design\n",
    "\n",
    "## General Flow\n",
    "\n",
    "> - We merge very sparse domains into an `\"other\"` class to ensure robust learning.\n",
    "> - We wrap `SentenceTransformers` in a custom `SentenceTransformerFeaturizer` so it can be used\n",
    ">   seamlessly inside an sklearn `Pipeline` and `RandomizedSearchCV`.\n",
    "> - The embeddings are generated using **`all-MiniLM-L6-v2`**, producing dense semantic representations\n",
    ">   for each case.\n",
    "> - **Normalization:** during embedding generation, the vectors are **L2-normalized** directly by the\n",
    ">   SentenceTransformers encoder (`normalize_embeddings=True`).\n",
    ">   This ensures that each embedding has unit length, making cosine similarity equivalent to\n",
    ">   the dot product and stabilizing training for linear models.\n",
    "> - On top of these normalized embeddings, we train a **regularized Logistic Regression (Logit Regression)**\n",
    ">   classifier â€” a simple yet powerful linear model that works well with dense features.\n",
    "> - The modelâ€™s regularization strength (`C`) is tuned via **stratified cross-validation**\n",
    ">   optimizing the **macro F1** score, which gives equal weight to all classes despite imbalance.\n",
    "\n",
    "### Adapting SentenceTransformers to scikit-learn\n",
    "\n",
    "> By default, **SentenceTransformers** models (e.g. `all-MiniLM-L6-v2`) operate outside of the\n",
    "standard scikit-learn API â€” they take a list of texts and return NumPy embeddings, not a\n",
    "DataFrame or sparse matrix.\n",
    ">\n",
    "> To integrate them cleanly with scikit-learnâ€™s ecosystem (pipelines, cross-validation,\n",
    "hyper-parameter search), we wrap the embedding step inside a **custom transformer**\n",
    "that follows the `fit` / `transform` interface.\n",
    "\n",
    "#### Key design ideas\n",
    "\n",
    "1. **Custom Transformer class**\n",
    "   We implement a small class called `SentenceTransformerFeaturizer`\n",
    "   that inherits from `BaseEstimator` and `TransformerMixin`.\n",
    "   - `fit()` simply loads or initializes the embedding model.\n",
    "   - `transform()` encodes the input texts into dense vectors using\n",
    "     `SentenceTransformer.encode()`.\n",
    "\n",
    "2. **Sklearn compatibility**\n",
    "   Because the class exposes `.fit()` and `.transform()`, it can be inserted as the first\n",
    "   stage in an `sklearn.Pipeline`:\n",
    "   ```python\n",
    "   pipe = Pipeline([\n",
    "       (\"embed\", SentenceTransformerFeaturizer(model_name=\"all-MiniLM-L6-v2\")),\n",
    "       (\"clf\", LogisticRegression(...))\n",
    "   ])\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:47:11.605095Z",
     "start_time": "2025-11-10T11:47:10.220818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Start from your deduped / filtered dataframe:\n",
    "# df has columns: id, text, domain\n",
    "\n",
    "def clean_case_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Light normalization for semantic similarity:\n",
    "    - ensure string\n",
    "    - normalize whitespace (incl. newlines) to single spaces\n",
    "    - strip\n",
    "    - lowercase\n",
    "    We keep punctuation and numbers â€“ they can be informative in legal texts.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if text is None else str(text)\n",
    "\n",
    "    # Collapse all whitespace (spaces, tabs, newlines) into a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Lowercase for stability\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "dataset_deduped[\"text_clean\"] = dataset_deduped[\"text\"].apply(clean_case_text)\n",
    "\n",
    "# Build helper mappings\n",
    "case_ids = dataset_deduped[\"id\"].tolist()\n",
    "id_to_index = {cid: i for i, cid in enumerate(case_ids)}\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# ============================================\n",
    "# Global config\n",
    "# ============================================\n",
    "\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "\n",
    "\n",
    "def _ensure_output_dir():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. Rare domains pooling\n",
    "# ============================================\n",
    "\n",
    "RARE_TO_OTHER = {\n",
    "    \"healthcare\",\n",
    "    \"intellectual property & communication\",\n",
    "    \"environmental & natural resources\",\n",
    "}\n",
    "\n",
    "\n",
    "def _merge_rare_domains(y: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Map very sparse domains into a single 'other' class.\n",
    "    \"\"\"\n",
    "    return y.apply(lambda label: \"other\" if label in RARE_TO_OTHER else label)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. Simple SentenceTransformer featurizer\n",
    "# ============================================\n",
    "\n",
    "class SentenceTransformerFeaturizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Sklearn transformer:\n",
    "    Expects a DataFrame with 'text_clean' column\n",
    "    -> returns sentence-transformer embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", text_col=\"text_clean\"):\n",
    "        self.model_name = model_name\n",
    "        self.text_col = text_col\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Load the sentence-transformers model once\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Support both DataFrame with text_col, or direct iterable of texts\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            texts = X[self.text_col].astype(str).tolist()\n",
    "        else:\n",
    "            texts = pd.Series(X).astype(str).tolist()\n",
    "\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=False,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        return np.asarray(embeddings)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. Training function\n",
    "# ============================================\n",
    "\n",
    "def train_domain_model(X, y):\n",
    "    '''\n",
    "    Train a text -> domain classifier with:\n",
    "    - rare domain pooling\n",
    "    - sentence-transformer embeddings\n",
    "    - random search on LogisticRegression(C)\n",
    "    - save best model in outputs/\n",
    "\n",
    "    @param X - pandas dataframe containing all the X values (must include 'text_clean')\n",
    "    @param y - pandas series containing all the y values (original domains)\n",
    "    @returns a trained model (Pipeline)\n",
    "    @rtype Pipeline\n",
    "    '''\n",
    "    _ensure_output_dir()\n",
    "\n",
    "    # --- 3.1 Merge rare domains for training labels ---\n",
    "    y_merged = _merge_rare_domains(y)\n",
    "\n",
    "    # --- 3.2 Define pipeline: embeddings -> logistic regression ---\n",
    "    pipeline = Pipeline([\n",
    "        (\"embed\", SentenceTransformerFeaturizer()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=200,\n",
    "            multi_class=\"auto\",\n",
    "            solver=\"lbfgs\",\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    # --- 3.3 Hyperparameter search space (on C only; embeddings are fixed) ---\n",
    "    param_distributions = {\n",
    "        \"clf__C\": loguniform(1e-2, 1e2),\n",
    "    }\n",
    "\n",
    "    # --- 3.4 Stratified CV for random search ---\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=10,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        refit=True,  # retrain best pipeline on all training data\n",
    "    )\n",
    "\n",
    "    # --- 3.5 Fit search on given TRAIN data ---\n",
    "    search.fit(X, y_merged)\n",
    "\n",
    "    # --- 3.6 Extract best model & save it ---\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"best_domain_model.joblib\")\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    # (Optional but nice) Save best params\n",
    "    best_params_path = os.path.join(OUTPUT_DIR, \"best_domain_model_params.json\")\n",
    "    with open(best_params_path, \"w\") as f:\n",
    "        json.dump(search.best_params_, f, indent=2)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. Evaluation function\n",
    "# ============================================\n",
    "\n",
    "def test_domain_model(model, X, y):\n",
    "    '''\n",
    "    Evaluate a trained model on a TEST set.\n",
    "\n",
    "    - Apply same rare-domain pooling on y\n",
    "    - Compute global & per-class metrics\n",
    "    - Compute micro-average ROC AUC & PR AUC\n",
    "    - Save metrics and ROC/PR plot into outputs/\n",
    "\n",
    "    @param model - Pipeline object model\n",
    "    @param X - pandas dataframe containing all the X test values\n",
    "    @param y - pandas series containing all the y true values\n",
    "    @returns a dictionary with model measures\n",
    "    @rtype dict\n",
    "    '''\n",
    "    _ensure_output_dir()\n",
    "\n",
    "    # --- 4.1 Align labels with training logic ---\n",
    "    y_true = _merge_rare_domains(y)\n",
    "\n",
    "    # --- 4.2 Predictions ---\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # --- 4.3 Global metrics ---\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # --- 4.4 Per-class metrics ---\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 4.5 ROC & PR curves (micro-average, global summary)\n",
    "    # ============================================\n",
    "\n",
    "    roc_auc_micro = None\n",
    "    pr_auc_micro = None\n",
    "\n",
    "    # Only if model supports predict_proba (LogReg does)\n",
    "    if hasattr(model, \"predict_proba\") or hasattr(model.named_steps.get(\"clf\", None), \"predict_proba\"):\n",
    "        # In a Pipeline, predict_proba is exposed at top-level if last step has it.\n",
    "        y_proba = model.predict_proba(X)\n",
    "\n",
    "        classes = model.classes_\n",
    "        y_true_bin = label_binarize(y_true, classes=classes)\n",
    "\n",
    "        # Micro-avg ROC\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_proba.ravel())\n",
    "        roc_auc_micro = auc(fpr, tpr)\n",
    "\n",
    "        # Micro-avg PR\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin.ravel(), y_proba.ravel())\n",
    "        pr_auc_micro = average_precision_score(y_true_bin, y_proba, average=\"micro\")\n",
    "\n",
    "        # --- Plot side-by-side ROC & PR ---\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "        # ROC curve\n",
    "        axes[0].plot(fpr, tpr, label=f\"Micro-avg ROC (AUC = {roc_auc_micro:.3f})\")\n",
    "        axes[0].plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
    "        axes[0].set_xlabel(\"False Positive Rate\")\n",
    "        axes[0].set_ylabel(\"True Positive Rate\")\n",
    "        axes[0].set_title(\"ROC Curve (micro-average)\")\n",
    "        axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "        # PR curve\n",
    "        axes[1].plot(recall, precision, label=f\"Micro-avg PR (AP = {pr_auc_micro:.3f})\")\n",
    "        axes[1].set_xlabel(\"Recall\")\n",
    "        axes[1].set_ylabel(\"Precision\")\n",
    "        axes[1].set_title(\"Precision-Recall Curve (micro-average)\")\n",
    "        axes[1].legend(loc=\"lower left\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(OUTPUT_DIR, \"domain_model_roc_pr_curves.png\")\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # ============================================\n",
    "    # 4.6 Save metrics to JSON\n",
    "    # ============================================\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"roc_auc_micro\": roc_auc_micro,\n",
    "        \"pr_auc_micro\": pr_auc_micro,\n",
    "        \"per_class_report\": report,\n",
    "    }\n",
    "\n",
    "    metrics_path = os.path.join(OUTPUT_DIR, \"domain_model_metrics.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2, default=float)\n",
    "\n",
    "    return metrics\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:11:31.487331Z",
     "start_time": "2025-11-10T12:11:31.484416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================\n",
    "# 5. Predict single sample by case_id\n",
    "# ============================================\n",
    "\n",
    "def predict_sample(model, case_id, data):\n",
    "    '''\n",
    "    This method should return a \"domain\" prediction for this sample.\n",
    "\n",
    "    @param model - Pipeline object model\n",
    "    @param case_id - the ID of the case we need to predict\n",
    "    @param data - dataframe containing at least ['case_id', 'text_clean']\n",
    "    @returns the predicted domain name\n",
    "    @rtype str\n",
    "    '''\n",
    "    row = data[data[\"id\"] == case_id]\n",
    "\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"case_id {case_id} not found in data\")\n",
    "\n",
    "    pred = model.predict(row)[0]\n",
    "    return pred\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Application"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose df has: ['case_id', 'text_clean', 'domain']\n",
    "df = dataset_deduped.copy()\n",
    "\n",
    "# 1) Stratified split on pooled labels\n",
    "y_all = df[\"domain\"]\n",
    "X_all = df[[\"id\", \"text_clean\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all,\n",
    "    y_all,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=_merge_rare_domains(y_all)\n",
    ")\n",
    "\n",
    "# 2) Train on train split\n",
    "model = train_domain_model(X_train, y_train)\n",
    "\n",
    "# 3) Evaluate on test split\n",
    "metrics = test_domain_model(model, X_test, y_test)\n",
    "print(metrics[\"accuracy\"], metrics[\"f1_macro\"])\n",
    "# print(metrics[\"per_class_report\"])  # if you want details"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:11:36.526037Z",
     "start_time": "2025-11-10T12:11:36.456188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 4) Predict one sample\n",
    "some_id = X_test[\"id\"].iloc[0]\n",
    "print(predict_sample(model, some_id, df))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civil rights, immigration, family\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12fdac2a-3557-4b5a-9d17-ae7a0f7ccb66",
     "showTitle": false,
     "title": ""
    },
    "id": "z2f2OYCc6hAj"
   },
   "outputs": [],
   "source": "# Results"
  },
  {
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6dbbb54-eb3c-41a1-a9f8-8575ab6513a1",
     "showTitle": false,
     "title": ""
    },
    "id": "koeB8NxI6hAj"
   },
   "cell_type": "markdown",
   "source": [
    "#Insights and Conclusions\n",
    "\n",
    "## Model Overview\n",
    "The final model combines **SentenceTransformers (`all-MiniLM-L6-v2`) embeddings** with a\n",
    "**regularized Logistic Regression (Logit Regression)** classifier.\n",
    "The embeddings are L2-normalized to preserve cosine geometry, and the model was tuned\n",
    "via **RandomizedSearchCV (5-fold, macro-F1 optimization)** to balance performance across domains.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Global Performance\n",
    "| Metric | Score |\n",
    "|:--|--:|\n",
    "| **Accuracy** | 0.718 |\n",
    "| **Macro F1** | 0.513 |\n",
    "| **ROC-AUC (micro)** | 0.942 |\n",
    "| **PR-AUC (micro)** | 0.786 |\n",
    "\n",
    "- The high **ROC-AUC** indicates strong global ranking ability (the model distinguishes positive vs. negative cases well overall).\n",
    "- **PR-AUC** shows reasonable precisionâ€“recall trade-off given class imbalance.\n",
    "- The **macro F1 â‰ˆ 0.51** reflects uneven per-class performance â€” expected due to sparsely represented domains.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Per-Domain Observations\n",
    "| Domain | F1-Score | Precision | Recall | Support | Key Notes |\n",
    "|:--|--:|--:|--:|--:|:--|\n",
    "| **Privacy** | **0.86** | 0.82 | 0.90 | 40 | Very strong semantic signal; model captures topical cues well. |\n",
    "| **Employment & Labor** | **0.85** | 0.85 | 0.85 | 40 | Consistent and robust category. |\n",
    "| **Civil Rights / Immigration / Family** | **0.83** | 0.87 | 0.79 | 34 | High precision and recall â€” good generalization. |\n",
    "| **Consumer Fraud / Securities** | 0.68â€“0.70 | â€“ | â€“ | 40 each | Moderate performance; legal and financial language overlap causes confusion. |\n",
    "| **Antitrust** | 0.63 | 0.62 | 0.64 | 25 | Acceptable given limited data. |\n",
    "| **Products Liability / Other / Discrimination / Criminal & Enforcement** | â‰¤ 0.40 | â€“ | â€“ | < 15 each | Poor recall â€” small sample size and semantic overlap with major domains. |\n",
    "\n",
    "- Classes with fewer than ~15 examples underperform due to **data scarcity** and limited representation during training.\n",
    "- â€œOtherâ€ and â€œDiscriminationâ€ domains likely require either more labeled data or hierarchical grouping.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Visual Diagnostics\n",
    "![Domain Model ROC & PR Curves](notebooks/outputs/domain_model_roc_pr_curves.png)\n",
    "\n",
    "- **ROC curves** confirm strong separability for dominant classes (privacy, employment).\n",
    "- **PR curves** reveal precision drop-off for minority classes, reinforcing the need for\n",
    "  additional samples or class-balancing techniques.\n",
    "\n",
    "---\n",
    "\n",
    "##Key Takeaways\n",
    "- The combination of **semantic embeddings + logit regression** provides a solid, interpretable baseline.\n",
    "- Strong results in well-represented domains validate that embeddings capture legal semantics effectively.\n",
    "- Performance drops for rare classes suggest:\n",
    "  - Expanding labeled data or synthetic augmentation,\n",
    "  - Trying hierarchical or multi-task classification,\n",
    "  - Exploring domain-specific legal embeddings (e.g., `legal-bert`).\n",
    "\n",
    "> **Overall:** the model generalizes well across main legal topics and forms a robust foundation\n",
    "for subsequent fine-tuning or domain-adapted improvements.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "interview_ds",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
